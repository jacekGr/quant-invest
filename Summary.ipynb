{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second stage summary\n",
    "\n",
    "In the first stage, we established that selecting a simple portfolio built with classical methods is more reliable than attempting to select or compose a portfolio using machine learning, in particular neural networks.\n",
    "\n",
    "During the second stage, we wanted to establish whether adding more relevant features to the training data and reducing the problem to a simple forecast (of future covariance or future returns) is a viable strategy. If this does not improve the base model, it will confirm our hypothesis that portfolio allocation should be performed based on fundamentals of portfolio theory and economics, rather than based on advanced analytics and forecasting.\n",
    "\n",
    "This summary consists of following parts:\n",
    "1. Base model performance testing (classical portfolio theory)\n",
    "2. Training advanced forecasting model\n",
    "  - dataset assembly\n",
    "  - model architecture definition\n",
    "  - training & validation of created model\n",
    "3. Comparison of test results between base and advanced model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from utils.data_loader import *\n",
    "\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.efficient_frontier import EfficientFrontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneYearTest(object):\n",
    "    \"\"\"\n",
    "    Scikit-learn style iterator returning training- and test-set indices,\n",
    "    where test set is one-year-long and training set consists of n_train_years\n",
    "    preceding the test set year.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, n_train_years: int=10):\n",
    "        self.index_years = df.index.year\n",
    "        self.unique_years = np.unique(self.index_years)\n",
    "        self.n_train_years = n_train_years\n",
    "        \n",
    "    @property\n",
    "    def train_years(self):\n",
    "        return set(self.unique_years[:self.idx])\n",
    "    \n",
    "    @property\n",
    "    def test_year(self):\n",
    "        return self.unique_years[self.idx]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.idx = self.n_train_years\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.idx < len(self.unique_years):\n",
    "            train_ids = self.index_years.isin(self.train_years)\n",
    "            test_ids = self.index_years == self.test_year\n",
    "            self.idx += 1\n",
    "            return train_ids, test_ids\n",
    "        else:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def portfolio_performance(allocation: np.array, fund_values: np.array) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculates total returns and daily returns volatility during entire period of provided fund values.\n",
    "    \"\"\"\n",
    "    allocation_value = np.sum(allocation * fund_values, axis=1) / np.sum(allocation)\n",
    "    period_returns = (allocation_value[-1] - allocation_value[0]) / allocation_value[0]\n",
    "    daily_returns = (allocation_value[1:] - allocation_value[:-1]) / allocation_value[:-1]\n",
    "    period_volatility = np.std(daily_returns)\n",
    "    return period_returns, period_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def portfolio_srri(allocation: np.array, fund_values: np.array) -> int:\n",
    "    \"\"\"\n",
    "    Calculates SRRI based on porfolio volatility \n",
    "    during last 5 years of provided fund_values,\n",
    "    as described in https://bit.ly/2RDVib9\n",
    "    \"\"\"\n",
    "    m = 260  # days in a year, as in the SRRI paper\n",
    "    T = 5*260  # days in 5 years, as in the SRRI paper\n",
    "    allocation_value = np.sum(allocation * fund_values[-T:], axis=1) / np.sum(allocation)\n",
    "    daily_returns = (allocation_value[1:] - allocation_value[:-1]) / allocation_value[:-1]\n",
    "    scaled_volatility = np.sqrt(m * np.sum((daily_returns - np.mean(daily_returns))**2) / (T-1))\n",
    "    if scaled_volatility >= 0.25:\n",
    "        return 7\n",
    "    elif scaled_volatility >= 0.15:\n",
    "        return 6\n",
    "    elif scaled_volatility >= 0.1:\n",
    "        return 5\n",
    "    elif scaled_volatility >= 0.05:\n",
    "        return 4\n",
    "    elif scaled_volatility >= 0.02:\n",
    "        return 3\n",
    "    elif scaled_volatility >= 0.005:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(funds_df: pd.DataFrame) -> np.array:\n",
    "    mu = mean_historical_return(funds_df)\n",
    "    S = CovarianceShrinkage(funds_df).ledoit_wolf()\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.efficient_return(0.1)\n",
    "    return ef.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARW</th>\n",
       "      <th>G</th>\n",
       "      <th>OP</th>\n",
       "      <th>ORR</th>\n",
       "      <th>ORW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daty</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>415.90</td>\n",
       "      <td>549.11</td>\n",
       "      <td>354.45</td>\n",
       "      <td>401.26</td>\n",
       "      <td>275.08</td>\n",
       "      <td>520.13</td>\n",
       "      <td>230.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>404.41</td>\n",
       "      <td>533.89</td>\n",
       "      <td>357.14</td>\n",
       "      <td>401.42</td>\n",
       "      <td>275.08</td>\n",
       "      <td>520.02</td>\n",
       "      <td>229.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>400.04</td>\n",
       "      <td>527.38</td>\n",
       "      <td>351.19</td>\n",
       "      <td>401.59</td>\n",
       "      <td>275.08</td>\n",
       "      <td>519.22</td>\n",
       "      <td>229.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>410.15</td>\n",
       "      <td>522.02</td>\n",
       "      <td>347.96</td>\n",
       "      <td>401.75</td>\n",
       "      <td>275.07</td>\n",
       "      <td>519.62</td>\n",
       "      <td>228.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>429.16</td>\n",
       "      <td>533.16</td>\n",
       "      <td>351.87</td>\n",
       "      <td>401.93</td>\n",
       "      <td>275.07</td>\n",
       "      <td>520.80</td>\n",
       "      <td>230.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AP     ARR     ARW       G      OP     ORR     ORW\n",
       "Daty                                                              \n",
       "2000-01-03  415.90  549.11  354.45  401.26  275.08  520.13  230.72\n",
       "2000-01-04  404.41  533.89  357.14  401.42  275.08  520.02  229.63\n",
       "2000-01-05  400.04  527.38  351.19  401.59  275.08  519.22  229.22\n",
       "2000-01-06  410.15  522.02  347.96  401.75  275.07  519.62  228.82\n",
       "2000-01-07  429.16  533.16  351.87  401.93  275.07  520.80  230.09"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funds_df = load_funds()\n",
    "funds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP</th>\n",
       "      <th>ARR</th>\n",
       "      <th>ARW</th>\n",
       "      <th>G</th>\n",
       "      <th>OP</th>\n",
       "      <th>ORR</th>\n",
       "      <th>ORW</th>\n",
       "      <th>srri</th>\n",
       "      <th>returns</th>\n",
       "      <th>volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>3.147186e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.972771e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.265175e-02</td>\n",
       "      <td>3.623375e-19</td>\n",
       "      <td>0.954375</td>\n",
       "      <td>4</td>\n",
       "      <td>0.111142</td>\n",
       "      <td>0.002708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>5.245311e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.766374e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.503978e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.887296</td>\n",
       "      <td>4</td>\n",
       "      <td>0.057131</td>\n",
       "      <td>0.002736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>3.601152e-14</td>\n",
       "      <td>4.015750e-15</td>\n",
       "      <td>1.662624e-17</td>\n",
       "      <td>1.446091e-17</td>\n",
       "      <td>8.635049e-18</td>\n",
       "      <td>4.590105e-14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.168538</td>\n",
       "      <td>0.001943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.782397e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.680585e-01</td>\n",
       "      <td>2.314928e-18</td>\n",
       "      <td>0.831942</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.047554</td>\n",
       "      <td>0.003428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>4.682031e-13</td>\n",
       "      <td>1.784696e-17</td>\n",
       "      <td>1.059090e-13</td>\n",
       "      <td>8.452873e-13</td>\n",
       "      <td>1.035153e-16</td>\n",
       "      <td>1.168058e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.069262</td>\n",
       "      <td>0.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>4.880799e-13</td>\n",
       "      <td>3.841907e-13</td>\n",
       "      <td>2.010943e-18</td>\n",
       "      <td>7.502117e-13</td>\n",
       "      <td>6.925339e-13</td>\n",
       "      <td>2.721481e-14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.002654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>8.845414e-13</td>\n",
       "      <td>8.258740e-21</td>\n",
       "      <td>3.258214e-18</td>\n",
       "      <td>3.603049e-18</td>\n",
       "      <td>1.605328e-18</td>\n",
       "      <td>8.021075e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.096736</td>\n",
       "      <td>0.003441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>8.767353e-14</td>\n",
       "      <td>1.169147e-12</td>\n",
       "      <td>7.322365e-17</td>\n",
       "      <td>1.233785e-16</td>\n",
       "      <td>5.395509e-17</td>\n",
       "      <td>3.380533e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.097111</td>\n",
       "      <td>0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.890710e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.715151e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.047065</td>\n",
       "      <td>0.002686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AP           ARR           ARW             G            OP  \\\n",
       "2010  3.147186e-17  0.000000e+00  2.972771e-03  0.000000e+00  4.265175e-02   \n",
       "2011  5.245311e-18  0.000000e+00  1.766374e-02  0.000000e+00  9.503978e-02   \n",
       "2012  3.601152e-14  4.015750e-15  1.662624e-17  1.446091e-17  8.635049e-18   \n",
       "2013  0.000000e+00  7.782397e-18  0.000000e+00  0.000000e+00  1.680585e-01   \n",
       "2014  4.682031e-13  1.784696e-17  1.059090e-13  8.452873e-13  1.035153e-16   \n",
       "2015  4.880799e-13  3.841907e-13  2.010943e-18  7.502117e-13  6.925339e-13   \n",
       "2016  8.845414e-13  8.258740e-21  3.258214e-18  3.603049e-18  1.605328e-18   \n",
       "2017  8.767353e-14  1.169147e-12  7.322365e-17  1.233785e-16  5.395509e-17   \n",
       "2018  0.000000e+00  1.890710e-13  0.000000e+00  5.715151e-13  0.000000e+00   \n",
       "\n",
       "               ORR       ORW  srri   returns  volatility  \n",
       "2010  3.623375e-19  0.954375     4  0.111142    0.002708  \n",
       "2011  0.000000e+00  0.887296     4  0.057131    0.002736  \n",
       "2012  4.590105e-14  1.000000     4  0.168538    0.001943  \n",
       "2013  2.314928e-18  0.831942     4 -0.047554    0.003428  \n",
       "2014  1.168058e-13  1.000000     4  0.069262    0.002734  \n",
       "2015  2.721481e-14  1.000000     3  0.006862    0.002654  \n",
       "2016  8.021075e-13  1.000000     3  0.096736    0.003441  \n",
       "2017  3.380533e-17  1.000000     3  0.097111    0.001755  \n",
       "2018  0.000000e+00  1.000000     3 -0.047065    0.002686  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dfs = []\n",
    "for train_ids, test_ids in OneYearTest(funds_df):\n",
    "    train_, test_ = funds_df[train_ids], funds_df[test_ids]\n",
    "    allocation = base_model(train_)\n",
    "    allocation_data = {fund: allocation[idx] for idx, fund in enumerate(funds_df.columns)}\n",
    "    srri = portfolio_srri(allocation, train_.values)\n",
    "    returns, volatility = portfolio_performance(allocation, test_.values)\n",
    "    performance_data = {'srri': srri, 'returns': returns, 'volatility': volatility}\n",
    "    result_dfs.append(\n",
    "        pd.DataFrame({**allocation_data, **performance_data}, index=[test_.index.year[0]])\n",
    "    )\n",
    "base_results_df = pd.concat(result_dfs, axis='index')\n",
    "base_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced model performance\n",
    "\n",
    "We will attempt to train a deep neural network, that will attempt to predict future returns as well as future fund value covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "import multiprocessing as mp\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation\n",
    "\n",
    "For our fund values, we calculate similar features to the ones mentioned by: *Bao, W., Yue, J., Rao, Y. (2017). A deep learning framework for financial time series\n",
    "using stacked autoencoders and long-short term memory.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_column_features = {\n",
    "    'MACD': lambda col: ta.trend.macd(col, n_fast=80, n_slow=160),\n",
    "    'BBL': lambda col: ta.volatility.bollinger_lband(col, n=120),\n",
    "    'BBH': lambda col: ta.volatility.bollinger_hband(col, n=120),\n",
    "    'EMA': lambda col: ta.trend.ema_indicator(col, n=240),\n",
    "}\n",
    "\n",
    "ohlc_column_features = {\n",
    "    # TODO\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 66.48it/s]\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.DataFrame(index=funds_df.index)\n",
    "for key in tqdm(fund_column_features):\n",
    "    for col in funds_df.columns:\n",
    "        features_df[f'{col}_{key}'] = fund_column_features[key](funds_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Target(object):\n",
    "    fund_returns: np.array\n",
    "    fund_covariance: np.array\n",
    "    ideal_allocation: np.array\n",
    "    ideal_returns: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_target(funds_df: pd.DataFrame) -> Target:\n",
    "    mu = mean_historical_return(funds_df)\n",
    "    S = CovarianceShrinkage(funds_df).ledoit_wolf()\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    ef.efficient_risk(0.1)\n",
    "    ideal_allocation = ef.weights\n",
    "    ideal_returns = ef.portfolio_performance()[0]\n",
    "    return Target(mu, S, ideal_allocation, ideal_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate all target data in parallel to save time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4541\n",
      "CPU times: user 5.11 s, sys: 428 ms, total: 5.54 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "YEAR_DAYS = 260\n",
    "\n",
    "dfs = [\n",
    "    funds_df[idx+1 : idx+1+YEAR_DAYS]\n",
    "    for idx in range(funds_df.iloc[:-YEAR_DAYS].shape[0])\n",
    "]\n",
    "with mp.Pool(processes=12) as pool:\n",
    "    targets = pool.map(calculate_target, dfs)\n",
    "\n",
    "print(len(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we extract information necessary for our experiment and back it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_target = np.zeros_like(funds_df[:-YEAR_DAYS])\n",
    "covariance_target = np.zeros(\n",
    "    (len(funds_df[:-YEAR_DAYS]), funds_df.shape[1]**2)\n",
    ")\n",
    "sample_weights = np.zeros(len(funds_df[:-YEAR_DAYS]))\n",
    "\n",
    "for idx, target in enumerate(targets):\n",
    "    returns_target[idx] = target.fund_returns.values.ravel()\n",
    "    covariance_target[idx] = target.fund_covariance.values.ravel()\n",
    "    sample_weights[idx] = target.ideal_returns  # years with higher returns are more important\n",
    "\n",
    "np.save('data/forecasting/returns_target.npy', returns_target)\n",
    "np.save('data/forecasting/covariance_target.npy', covariance_target)\n",
    "np.save('data/forecasting/sample_weights.npy', sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add past targets to our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_features = np.zeros_like(funds_df)\n",
    "returns_features[:YEAR_DAYS] = np.nan\n",
    "returns_features[YEAR_DAYS:] = returns_target\n",
    "\n",
    "covariance_features = np.zeros(\n",
    "    (len(funds_df), funds_df.shape[1]**2)\n",
    ")\n",
    "covariance_features[:YEAR_DAYS] = np.nan\n",
    "covariance_features[YEAR_DAYS:] = covariance_target\n",
    "\n",
    "weights_features = np.zeros(len(funds_df))\n",
    "weights_features[:YEAR_DAYS] = np.nan\n",
    "weights_features[YEAR_DAYS:] = sample_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)\n",
    "cuda_device = 0\n",
    "assert(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers\n",
    "        )\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = np.hstack([features_df.values, returns_features, covariance_features, weights_features.reshape(-1, 1)])\n",
    "features_valid = np.all(~np.isnan(all_features), axis=1)\n",
    "feature_scaler = StandardScaler()\n",
    "all_features[features_valid] = feature_scaler.fit_transform(all_features[features_valid])\n",
    "\n",
    "all_targets = np.hstack([returns_target, covariance_target])\n",
    "targets_valid = np.all(~np.isnan(all_targets), axis=1)\n",
    "target_scaler = StandardScaler()\n",
    "all_targets[targets_valid] = target_scaler.fit_transform(all_targets[targets_valid])\n",
    "\n",
    "# unlike features, targets are only generated when they are valid\n",
    "assert(sum(targets_valid) == len(targets_valid))\n",
    "assert(len(targets_valid) < len(features_valid))\n",
    "# so last year of features cannot have any target associated with it (no data to compute the target)\n",
    "all_features = all_features[:len(targets_valid)]\n",
    "features_valid = features_valid[:len(targets_valid)]\n",
    "\n",
    "# this is created for one-year-validation to have a correct index for data splitting\n",
    "meta_df = pd.DataFrame({'valid': features_valid}, index=funds_df.iloc[:len(features_valid)].index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
